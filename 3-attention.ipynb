{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tikzmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext tikzmagic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".red { color: #E41A1C; }\n",
       ".orange { color: #FF7F00 }\n",
       ".yellow { color: #FFC020 }         \n",
       ".green { color: #4DAF4A }                  \n",
       ".blue { color: #377EB8; }\n",
       ".purple { color: #984EA3 }       \n",
       "\n",
       "ctb_global_show div.ctb_hideshow.ctb_show {\n",
       "    display: inline;\n",
       "} \n",
       "     \n",
       "#for reveal         \n",
       ".aside .controls, .reveal .controls {\n",
       "    display: none !important;                            \n",
       "    width: 0px !important;\n",
       "    height: 0px !important;\n",
       "}\n",
       "    \n",
       ".rise-enabled .reveal .slide-number {\n",
       "    right: 25px;\n",
       "    bottom: 25px;                        \n",
       "    font-size: 200%;     \n",
       "    color: #377EB8;                        \n",
       "}         \n",
       "         \n",
       ".rise-enabled .reveal .progress span {\n",
       "    background: #377EB8;\n",
       "}     \n",
       "         \n",
       ".cite {\n",
       "    float: right;\n",
       "    color: #377EB8;    \n",
       "}         \n",
       "         \n",
       ".rise-enabled .rendered_html table {\n",
       "    font-size: 30px;\n",
       "}         \n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!--\n",
       "div.tabContent {\n",
       "    padding: 0px;\n",
       "    background: #ffffff;     \n",
       "    border: 0px;                        \n",
       "}  \n",
       "         \n",
       ".left {\n",
       "    float: left;\n",
       "    width: 50%;\n",
       "    vertical-align: text-top;\n",
       "}\n",
       "\n",
       ".right {\n",
       "    margin-left: 50%;\n",
       "    vertical-align: text-top;                            \n",
       "}    \n",
       "         \n",
       ".veryright {\n",
       "    margin-left: 70%;\n",
       "    vertical-align: text-top;                            \n",
       "}          \n",
       "               \n",
       ".small {         \n",
       "    zoom: 0.9;\n",
       "    -ms-zoom: 0.9;\n",
       "    -webkit-zoom: 0.9;\n",
       "    -moz-transform:  scale(0.9,0.9);\n",
       "    -moz-transform-origin: left center;  \n",
       "}          \n",
       "         \n",
       ".verysmall {         \n",
       "    zoom: 0.75;\n",
       "    -ms-zoom: 0.75;\n",
       "    -webkit-zoom: 0.75;\n",
       "    -moz-transform:  scale(0.75,0.75);\n",
       "    -moz-transform-origin: left center;  \n",
       "}         \n",
       "   \n",
       "        \n",
       ".tiny {         \n",
       "    zoom: 0.6;\n",
       "    -ms-zoom: 0.6;\n",
       "    -webkit-zoom: 0.6;\n",
       "    -moz-transform:  scale(0.6,0.6);\n",
       "    -moz-transform-origin: left center;  \n",
       "}         \n",
       "         \n",
       "         \n",
       ".rendered_html blockquote {\n",
       "    border-left-width: 0px;\n",
       "    padding: 15px;\n",
       "    margin: 0px;    \n",
       "    width: 100%;                            \n",
       "}         \n",
       "         \n",
       ".rendered_html th {\n",
       "    padding: 0.5em;  \n",
       "    border: 0px;                            \n",
       "}         \n",
       "         \n",
       ".rendered_html td {\n",
       "    padding: 0.25em;\n",
       "    border: 0px;                                                        \n",
       "}        \n",
       "    \n",
       ".present .top {\n",
       "    position: fixed !important;\n",
       "    top: 0 !important;                                   \n",
       "}                  \n",
       "    \n",
       ".present .rendered_html * + p, .present .rendered_html p, .present .rendered_html * + br, .present .rendered_html br {\n",
       "    margin: 0.5em 0;                            \n",
       "}  \n",
       "         \n",
       ".present tr, .present td {\n",
       "    border: 0px;\n",
       "    padding: 0.35em;                            \n",
       "}      \n",
       "         \n",
       ".present th {\n",
       "    border: 1px;\n",
       "}\n",
       "         \n",
       "tbody {\n",
       "    font-size: 65%;                            \n",
       "}         \n",
       "         \n",
       "present .prompt {\n",
       "    min-width: 0px !important;\n",
       "    transition-duration: 0s !important;\n",
       "}     \n",
       "         \n",
       ".prompt {\n",
       "    min-width: 0px !important;\n",
       "    transition-duration: 0s !important;                            \n",
       "}         \n",
       "         \n",
       ".rise-enabled .cell li {\n",
       "    line-height: 135%;\n",
       "}\n",
       "         \n",
       ".reveal pre code {\n",
       "    font-size: 50%;\n",
       "    line-height: normal;\n",
       "}   \n",
       "-->"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "require(['base/js/utils'],\n",
       "function(utils) {\n",
       "   utils.load_extensions('calico-spell-check', 'calico-document-tools', 'calico-cell-tools');\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\n",
       "% Misc Math\n",
       "\\let\\union\\cup\n",
       "\\let\\dom\\mathcal\n",
       "\\let\\set\\dom \n",
       "\\newcommand\\ls[1]{\\verb~#1~}\n",
       "\\def\\R{\\mathbb{R}}\n",
       "\\def\\N{\\mathbb{N}}\n",
       "\\def\\E{\\mathbb{E}}\n",
       "\\def\\C{\\mathbb{C}}\n",
       "\\renewcommand\\vec[1]{{\\mathbf{#1}}}\n",
       "\\let\\mat\\mathbf\n",
       "\\let\\ten\\mathcal\n",
       "\\let\\infinity\\infty \n",
       "\\let\\grad\\nabla\n",
       "\\let\\mul\\odot\n",
       "\\newcommand\\onehot[1]{\\vec{1}_{#1}}\n",
       "\n",
       "% Optimization\n",
       "\\def\\loss{\\mathcal{L}}\n",
       "\\def\\params{{\\vec{\\theta}}}\n",
       "\\def\\globalloss{\\mathfrak{L}}\n",
       "\n",
       "% Neural Network Modules\n",
       "\\newcommand{\\module}[1]{\\verb~#1~}\n",
       "\\def\\ndot{\\module{dot}}\n",
       "\\def\\sigm{\\module{sigm}}\n",
       "\\def\\nlog{\\module{log}}\n",
       "\\def\\relu{\\module{ReLU}}\n",
       "\\def\\rnn{\\module{RNN}}\n",
       "\\def\\lstm{\\module{LSTM}}\n",
       "\\def\\cell{\\module{cell}}\n",
       "\\def\\cons{\\module{concat}}\n",
       "\\def\\split{\\module{split}}\n",
       "\\def\\mul{\\module{matmul}} % fixme: clash with component-wise mul\n",
       "\\let\\matmul\\mul\n",
       "\\def\\ntanh{\\module{tanh}}\n",
       "\\def\\nsoftmax{\\module{softmax}}\n",
       "\\def\\nunify{\\module{sim}}\n",
       "\n",
       "\n",
       "% Math operators\n",
       "\\DeclareMathOperator{\\softmax}{softmax}\n",
       "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
       "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
       "\\let\\sigmoid\\sigma\n",
       "\\DeclareMathOperator{\\unify}{unify}\n",
       "\\DeclareMathOperator{\\real}{real}\n",
       "\\DeclareMathOperator{\\imag}{imag}\n",
       "\\DeclareMathOperator{\\diag}{diag}\n",
       "\n",
       "\n",
       "\n",
       "\\require{color}\n",
       "\\definecolor{nice-red}{RGB}{228, 26, 28}\n",
       "\\definecolor{nice-orange}{RGB}{255, 127, 0}\n",
       "\\definecolor{nice-yellow}{RGB}{255, 192, 32}\n",
       "\\definecolor{nice-green}{RGB}{77, 175, 74}\n",
       "\\definecolor{nice-blue}{RGB}{55, 126, 184}\n",
       "\\definecolor{nice-purple}{RGB}{152, 78, 163}\n",
       "\n",
       "% TODOs\n",
       "\\def\\blah{\\bf\\color{red}???}\n",
       "\\def\\todo{\\bf\\color{red}TODO}\n",
       "\\def\\toref{\\bf\\color{nice-purple}TOREF}\n",
       "$$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"preamble.ipynb\"\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from dl4nlp.util import *\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.nn import Parameter\n",
    "from dl4nlp.tikz import *\n",
    "import IPython.display\n",
    "IPython.display.display_latex(IPython.display.Latex(filename=\"tex/macros.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<h1>Deep Learning for Natural Language Processing III</h1>\n",
    "<h2>Attention</h2>\n",
    "<br>\n",
    "Tim Rocktäschel<br>\n",
    "<a href=\"https://rockt.github.com\">rockt.github.com</a> <a href=\"mailto:tim.rocktaschel@cs.ox.ac.uk\">tim.rocktaschel@cs.ox.ac.uk</a> <a href=\"https://twitter.com/_rockt\">Twitter: @_rockt</a><br>\n",
    "<img src=\"./figures/oxford.svg\" width=30%><br>\n",
    "2nd Int'l Summer School on Data Science, Split, Croatia<br>\n",
    "27th September 2017<br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use-case: Recognizing Textual Entailment (RTE)\n",
    "\n",
    "- **A wedding party is taking pictures**\n",
    "  - There is a funeral\t\t\t\t\t: **<span class=red>Contradiction</span>**\n",
    "  - They are outside\t\t\t\t\t: **<span class=blue>Neutral</span>**\n",
    "  - Someone got married\t\t\t\t    : **<span class=green>Entailment</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### State of the Art until 2015\n",
    "\n",
    "- Engineered natural language processing pipelines\n",
    "- Various external resources\n",
    "- Specialized subcomponents\n",
    "- Extensive manual creation of **features**:\n",
    "  - Negation detection, word overlap, part-of-speech tags, dependency parses, alignment, unaligned matching, chunk alignment, synonym, hypernym, antonym, denotation graph\n",
    "  \n",
    "<div class=cite>[Lai and Hockenmaier, 2014, Jimenez et al., 2014, Zhao et al., 2014, Beltagy et al., 2015, ...]</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neural Networks for RTE\n",
    "\n",
    "**Previous RTE corpora**:\n",
    "- Tiny data sets (1k-10k examples)\n",
    "- Partly synthetic examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Stanford Natural Inference Corpus (SNLI)**:\n",
    "- 500k sentence pairs\n",
    "- Two orders of magnitude larger than existing RTE data set\n",
    "- All examples generated by humans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Independent Sentence Encoding\n",
    "\n",
    "Same LSTM encodes premise and hypothesis\n",
    "\n",
    "<img src=\"./figures/3-attention/rte_encoding.svg\" width=60%/> \n",
    "\n",
    "<div class=cite>[Bowman et al, 2015]</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> You can’t cram the meaning of a whole\n",
    "%&!\\$# sentence into a single \\$&!#* vector!\n",
    ">\n",
    "> -- <cite>Raymond J. Mooney</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Independent Sentence Encoding\n",
    "\n",
    "<img src=\"./figures/3-attention/mlp.svg\" width=60%/> \n",
    "\n",
    "<div class=cite>[Bowman et al, 2015]</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "| Model | k | θ<sub>W+M</sub> | θ<sub>M</sub> | Train | Dev | Test |\n",
    "|-|-|-|-|-|-|-|\n",
    "| LSTM [<span class=blue>Bowman et al.</span>] | 100 | \\\\(\\approx\\\\)10M | 221k | 84.4 | - | 77.6|\n",
    "| Classifier [<span class=blue>Bowman et al.</span>]| - | - | - | 99.7 | - | 78.2|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional Endcoding\n",
    "\n",
    "<img src=\"figures/3-attention/conditional_encoding.svg\" width=60%/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{align}\n",
    "\\text{softmax}(\\text{tanh}(\\mathbf{W}\\mathbf{h}_N))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "| Model | k | θ<sub>W+M</sub> | θ<sub>M</sub> | Train | Dev | Test |\n",
    "|-|-|-|-|-|-|-|\n",
    "| LSTM [<span class=blue>Bowman et al.</span>] | 100 | \\\\(\\approx\\\\)10M | 221k | 84.4 | - | 77.6|\n",
    "| Classifier [<span class=blue>Bowman et al.</span>]| - | - | - | 99.7 | - | 78.2|\n",
    "| Conditional Endcoding | 159 | 3.9M | 252k | 84.4 | 83.0 | 81.4|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attention\n",
    "\n",
    "<img src=\"./figures/3-attention/attention_encoding.svg\" width=60%/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=small>\n",
    "\\begin{align}\n",
    "  \\mathbf{M} &= \\tanh(\\mathbf{W}^y\\mathbf{Y}+ \\mathbf{W}^h\\mathbf{h}_N\\mathbf{1}^T_L)&\\mathbf{M}&\\in\\mathbb{R}^{k \\times L}\\\\\n",
    "  \\alpha &= \\text{softmax}(\\mathbf{w}^T\\mathbf{M})&\\alpha&\\in\\mathbb{R}^L\\\\\n",
    "  \\mathbf{r} &= \\mathbf{Y}\\alpha^T&\\mathbf{r}&\\in\\mathbb{R}^k\n",
    "\\end{align}\n",
    "</div>\n",
    "\n",
    "<div class=cite> [Graves 2013, Bahdanau et al. 2015]</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img  src=\"./figures/3-attention/camel.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contextual Understanding\n",
    "<img  src=\"./figures/3-attention/pink.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "| Model | k | θ<sub>W+M</sub> | θ<sub>M</sub> | Train | Dev | Test |\n",
    "|-|-|-|-|-|-|-|\n",
    "| LSTM [<span class=blue>Bowman et al.</span>] | 100 | \\\\(\\approx\\\\)10M | 221k | 84.4 | - | 77.6|\n",
    "| Classifier [<span class=blue>Bowman et al.</span>]| - | - | - | 99.7 | - | 78.2|\n",
    "| Conditional Encoding | 159 | 3.9M | 252k | 84.4 | 83.0 | 81.4|\n",
    "| Attention | 100 | 3.9M | 242k | 85.4 | 83.2 | 82.3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fuzzy Attention\n",
    "<img  src=\"./figures/3-attention/mimes.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word-by-word Attention\n",
    "\n",
    "<img src=\"./figures/3-attention/word_attention_encoding.svg\" width=60%/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=small>\n",
    "\\begin{align}\n",
    "  \\mathbf{M}_t &= \\tanh(\\mathbf{W}^y\\mathbf{Y}+(\\mathbf{W}^h\\mathbf{h}_t+\\mathbf{W}^r\\mathbf{r}_{t-1})\\mathbf{1}^T_L) & \\mathbf{M}_t &\\in\\mathbb{R}^{k\\times L}\\\\\n",
    "  \\alpha_t &= \\text{softmax}(\\mathbf{w}^T\\mathbf{M}_t)&\\alpha_t&\\in\\mathbb{R}^L\\\\\n",
    "  \\mathbf{r}_t &= \\mathbf{Y}\\alpha^T_t + \\tanh(\\mathbf{W}^t\\mathbf{r}_{t-1})&\\mathbf{r}_t&\\in\\mathbb{R}^k\n",
    "\\end{align}\n",
    "</div>\n",
    "<div class=cite>[Bahdanau et al. 2015, Hermann et al. 2015, Rush et al. 2015, Rocktäschel et al. 2016]</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reordering\n",
    "<img src=\"./figures/3-attention/reordering.png\" width=40%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Garbage Can = Trashcan\n",
    "<img  src=\"./figures/3-attention/trashcan.png\" width=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kids =  Girl + Boy\n",
    "<img  src=\"./figures/3-attention/kids.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Snow is outside\n",
    "<img  src=\"./figures/3-attention/snow.png\" width=90%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "| Model | k | θ<sub>W+M</sub> | θ<sub>M</sub> | Train | Dev | Test |\n",
    "|-|-|-|-|-|-|-|\n",
    "| LSTM [<span class=blue>Bowman et al.</span>] | 100 | \\\\(\\approx\\\\)10M | 221k | 84.4 | - | 77.6|\n",
    "| Classifier [<span class=blue>Bowman et al.</span>]| - | - | - | 99.7 | - | 78.2|\n",
    "| Conditional Encoding | 159 | 3.9M | 252k | 84.4 | 83.0 | 81.4|\n",
    "| Attention | 100 | 3.9M | 242k | 85.4 | 83.2 | 82.3 |\n",
    "| Word-by-word Attention | 100 | 3.9M | 252k | 85.3 | **83.7** | **83.5** |"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "livereveal": {
   "controls": "false",
   "progress": "true",
   "theme": "white",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
